# Deep Learning Fundamentals

## Overview
Deep learning fundamentals provide the mathematical and practical foundation for modern computer vision. Understanding neural networks, backpropagation, and optimization is crucial before diving into specialized architectures.

## Concepts :
- Neural Networks (Perceptron, Multilayer Perceptron)
- Backpropagation algorithm and gradient descent
- Loss functions (MSE, Cross-entropy, Hinge loss)
- Optimizers (SGD, Adam, RMSprop)
- Regularization techniques (Dropout, L1/L2, Batch Normalization)
- Activation functions and their properties
- Forward and backward propagation

## Projects :
- [Project 1: Neural Network from Scratch](Project%201/README.md) - Build and train a neural network without frameworks
- [Project 2: Image Classification with MLP](Project%202/README.md) - Multi-layer perceptron for CIFAR-10 classification
- [Project 3: Optimization Algorithms Comparison](Project%203/README.md) - Compare different optimizers and learning strategies
- [Project 4: Regularization Techniques](Project%204/README.md) - Implement and compare regularization methods

## Courses :
- Deep Learning Specialization by Andrew Ng (Coursera)
- Neural Networks and Deep Learning by deeplearning.ai
